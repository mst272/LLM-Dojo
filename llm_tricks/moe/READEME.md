# Make MOE step by step

ä»Žé›¶æž„å»ºä¸€ä¸ªMOEä»£ç å­˜æ”¾äºŽ **make_moe_step_by_step.ipynb**æ–‡ä»¶ä¸‹ã€‚å…¶ä¸­æœ‰è¯¦ç»†çš„ä»£ç æ³¨é‡Šï¼ŒæŽ¨èç»“åˆæŠ€æœ¯åšå®¢é˜…è¯»ï¼Œå› ä¸ºåšå®¢ä¸­æ‰‹ç”»äº†è®¸å¤šå›¾ä»¥æ›´å¥½åœ°ç†è§£ã€‚

## ðŸ˜¸æŠ€æœ¯åšå®¢é“¾æŽ¥

- [ä»Žé›¶æž„å»ºä¸€ä¸ªMOE](https://zhuanlan.zhihu.com/p/701777558)



## è¡¥å……

åšå®¢ä¸­æ²¡æåˆ°çš„ä¸€ç‚¹æ˜¯ Expert Capacityã€‚å¤§æ¦‚æ„æ€å°±æ˜¯ä¸ºäº†é˜²æ­¢æ‰€æœ‰tokenséƒ½è¢«ä¸€ä¸ªæˆ–å‡ ä¸ªexpertå¤„ç†ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€ä¸ªä¸“å®¶å®¹é‡ã€‚å¦‚æžœæŸä¸ªä¸“å®¶å¤„ç†è¶…è¿‡å®¹é‡çš„tokensåŽå°±ä¼šç»™ä»–æˆªæ–­ï¼Œä¸‹é¢ç»™å‡ºä¸€ä¸ªç®€å•çš„ä»£ç ç¤ºä¾‹ï¼Œå®žé™…ç”Ÿäº§ä¸­ä¼šæœ‰æ›´é«˜çº§å¤æ‚çš„ç­–ç•¥,
ä¾‹å¦‚åœ¨https://arxiv.org/abs/2101.03961 ä¸­è®¨è®ºçš„switch transformeræž¶æž„ã€‚

æˆ‘ä»¬ç®€å•çš„ä»‹ç»ä»£ç å¦‚ä¸‹ï¼Œä¸Žæˆ‘ä»¬æŠ€æœ¯åšå®¢ä¸­è®²çš„SparseMoEåŸºæœ¬ç›¸åŒï¼Œåªæ˜¯åŠ äº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œåœ¨ä»£ç æ³¨é‡Šä¸­ä¹Ÿå·²æ ‡æ˜Žã€‚
```python
class SparseMoE(nn.Module):
    def __init__(self, n_embed, num_experts, top_k, capacity_factor=1.0):
        super(SparseMoE, self).__init__()
        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)
        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])
        self.top_k = top_k
        self.capacity_factor = capacity_factor
        self.num_experts = num_experts
    
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        gating_output, indices = self.router(x)
        final_output = torch.zeros_like(x)

        flat_x = x.view(-1, x.size(-1))  
        flat_gating_output = gating_output.view(-1, gating_output.size(-1))

        tokens_per_batch = batch_size * seq_len * self.top_k
        # å®šä¹‰ä¸“å®¶å®¹é‡
        expert_capacity = int((tokens_per_batch / self.num_experts) * self.capacity_factor)

        updates = torch.zeros_like(flat_x)

        for i, expert in enumerate(self.experts):
            expert_mask = (indices == i).any(dim=-1)
            flat_mask = expert_mask.view(-1)
            selected_indices = torch.nonzero(flat_mask).squeeze(-1)
            
            # è¿›è¡Œå®¹é‡åˆ¤æ–­
            limited_indices = selected_indices[:expert_capacity] if selected_indices.numel() > expert_capacity else selected_indices
            if limited_indices.numel() > 0:
                expert_input = flat_x[limited_indices]
                expert_output = expert(expert_input)

                gating_scores = flat_gating_output[limited_indices, i].unsqueeze(1)
                weighted_output = expert_output * gating_scores

                updates.index_add_(0, limited_indices, weighted_output)

        # Reshape updates to match the original dimensions of x
        final_output += updates.view(batch_size, seq_len, -1)

        return final_output

```